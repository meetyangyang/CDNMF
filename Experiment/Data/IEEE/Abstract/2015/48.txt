This paper considers situations in which a team of mobile sensor platforms autonomously explores an environment to detect and localize an unknown number of targets. Individual sensors may be unreliable;  failing to detect objects within the field-of-view;  returning false positive measurements to clutter objects;  and being unable to disambiguate true targets. In this setting;  data association is difficult. We utilize the PHD filter for multitarget localization;  simultaneously estimating the number of objects and their locations within the environment without the need to explicitly consider data association. Using sets of potential actions generated at multiple length scales for each robot;  the team selects the joint action that maximizes the expected information gain over a finite time horizon. This is computed as the mutual information between the set of targets and the binary events of receiving no detections;  effectively hedging against uninformative actions in a computationally tractable manner. We frame the controller as a receding-horizon problem. We demonstrate the real-world applicability of the proposed autonomous exploration strategy through hardware experiments;  exploring an office environment with a team of ground robots. We also conduct a series of simulated experiments;  varying the planning method;  target cardinality;  environment;  and sensor modality. 