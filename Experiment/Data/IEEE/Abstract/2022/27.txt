It is ambitious to develop a brain-controlled robotic arm for some patients with motor impairments to perform activities of daily living using brainâ€“computer interfaces (BCIs). Despite much progress achieved;  this mission is still very challenging mainly due to the poor decoding performance of BCIs. The problem is even exacerbated in the case of noninvasive BCIs. A shared control strategy is developed in this work to realize flexible robotic arm control for reach and grasp of multiple objects. With the intelligent assistance provided by robot vision;  the subject was only required to finish gross reaching movement and target selection using a simple motor imagery-based BCI with binary output. Along with the user control;  the robotic arm;  which identified and localized potential targets within the workspace in the background;  was capable of providing both trajectory correction in the reaching phase to reduce trajectory redundancy and autonomous grasping assistance in the phase of grasp. Ten subjects participated in the experiments containing one session of two-block grasping tasks with fixed locations and another one of randomly placed three-block grasping tasks. The results of the experiments demonstrated substantial improvement with the shared control system. Compared with the single BCI control;  the success rate of shared control was significantly higher (\n<inline-formula xmlns:mml=\http://www.w3.org/1998/Math/MathML\ xmlns:xlink=\http://www.w3.org/1999/xlink\> <tex-math notation=\LaTeX\>$p &lt; 0.001$ </tex-math></inline-formula>\n for group performance);  and moreover;  the task completion time and perceived difficulty were significantly lower (\n<inline-formula xmlns:mml=\http://www.w3.org/1998/Math/MathML\ xmlns:xlink=\http://www.w3.org/1999/xlink\> <tex-math notation=\LaTeX\>$p &lt; 0.001$ </tex-math></inline-formula>\n for group performance both);  indicating the potential of our proposed shared control system in real applications.