Many applications for the automated diagnosis of plant disease have been developed based on the success of deep learning techniques. However;  these applications often suffer from overfitting;  and the diagnostic performance is drastically decreased when used on test data sets from new environments. In this article;  we propose LeafGAN;  a novel image-to-image translation system with own attention mechanism. LeafGAN generates a wide variety of diseased images via transformation from healthy images;  as a data augmentation tool for improving the performance of plant disease diagnosis. Due to its own attention mechanism;  our model can transform only relevant areas from images with a variety of backgrounds;  thus enriching the versatility of the training images. Experiments with five-class cucumber disease classification show that data augmentation with vanilla CycleGAN cannot help to improve the generalization;  i.e.;  disease diagnostic performance increased by only 0.7% from the baseline. In contrast;  LeafGAN boosted the diagnostic performance by 7.4%. We also visually confirmed that the generated images by our LeafGAN were much better quality and more convincing than those generated by vanilla CycleGAN. The code is available publicly at \n<uri xmlns:mml=\http://www.w3.org/1998/Math/MathML\ xmlns:xlink=\http://www.w3.org/1999/xlink\>https://github.com/IyatomiLab/LeafGAN</uri>\n. \n<italic xmlns:mml=\http://www.w3.org/1998/Math/MathML\ xmlns:xlink=\http://www.w3.org/1999/xlink\>