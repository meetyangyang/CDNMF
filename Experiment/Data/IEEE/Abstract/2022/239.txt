This article investigates the multirobot cooperative navigation problem based on raw visual observations. A fully end-to-end learning framework is presented;  which leverages graph neural networks to learn local motion coordination and utilizes deep reinforcement learning to generate visuomotor policy that enables each robot to move to its goal without the need of environment map and global positioning information. Experimental results show that;  with a few tens of robots;  our approach achieves comparable performance with the state-of-the-art imitation learning-based approaches with bird-view state inputs. We also illustrate our generalizability to crowded and large environments and our scalability to ten times number of the training robots. In addition;  we demonstrate that our model trained for multirobot case can also improve the success rate in the single-robot navigation task in unseen environments. 