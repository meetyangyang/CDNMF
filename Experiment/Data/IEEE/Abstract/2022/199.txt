To tackle the poor localization accuracy of multimobile robots caused by non-line-of-sight (NLOS) errors in a complex indoor environment and to meet the real-time requirement;  this article proposes a multimobile robot cooperative localization system using ultrawideband (UWB) sensor and GPU hardware acceleration. First;  a UWB multinode ranging network is established to obtain the relative distance information between robots and anchors. Then;  the line-of-sight (LOS) and NLOS errors in distance information are effectively mitigated by using the proposed UWB ranging error mitigation algorithm based on the Bayesian filter. A cooperative particle filter (PF) localization algorithm based on the Gibbs sampling is designed to estimate the position information of each robot at any time. Finally;  in order to improve the real-time performance of the collaborative localization system;  a parallel Gibbs collaborative localization algorithm that can be accelerated by GPU is proposed considering the characteristics of GPU hardware and CUDA programming model. The experimental results of three TurtleBot2 mobile robots in real scene show that the proposed multimobile robot cooperative localization system using UWB technology can estimate the position information of each robot robustly and accurately;  and the localization accuracy is superior to that of the popular extended Kalman filter (EKF) and PF algorithms. It is shown through further evaluations that the proposed parallel algorithm achieves about 3.2 times acceleration effect in the scenarios of three mobile robots. The speed gain is found more significant with more robots;  which substantially improves the real-time performance of the cooperative localization system. In the test with seven mobile robots;  the speedup is as high as 11.9;  that is;  the execution time of the algorithm is only 8.39% of that of the original algorithm. 