The environment around general-purpose service robots has a dynamic nature. Accordingly;  even the robotâ€™s programmer cannot predict all the possible external failures which the robot may confront. This research proposes an online incremental learning method that can be further used to autonomously handle external failures originating from a change in the environment. Existing research typically offers special-purpose solutions. Furthermore;  the current incremental online learning algorithms cannot generalize well with just a few observations. In contrast;  our method extracts a set of hypotheses;  which can then be used for finding the best recovery behavior at each failure state. The proposed argumentation-based online incremental learning approach uses an abstract and bipolar argumentation framework to extract the most relevant hypotheses and model the defeasibility relation between them. This leads to a novel online incremental learning approach that overcomes the addressed problems and can be used in different domains including robotic applications. We have compared our proposed approach with state-of-the-art online incremental learning approaches;  an approximation-based reinforcement learning method;  and several online contextual bandit algorithms. The experimental results show that our approach learns more quickly with a lower number of observations and also has higher final precision than the other methods. 