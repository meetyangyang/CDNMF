A dual-gripper robotic cell consists of multiple processing machines and one material handling robot;  which can perform an unloading or a loading task one at a time but can hold two parts at the same time. We address a scheduling problem of the robotic cell that determines a robot task sequence when two part types are processed in a different set of machines and all machines have variable processing times within a given interval. The objective is to minimize the makespan. This study proposes a learning-based method;  i.e.;  a reinforcement learning (RL) approach;  for the first time;  to address a dual-gripper robotic cell scheduling problem. The problem is modeled with a Petri net;  a graphical and mathematical modeling tool;  which is used as an environment in RL. The states;  actions;  and rewards are defined by using flow shop scheduling properties;  features from a Petri net;  and knowledge from previous studies of scheduling robotized tools. Then;  the RL approach is compared to the first-in-first-out (FIFO) rule;  which is generally used in practice;  a swap sequence;  which is widely used for cyclic scheduling of dual-gripper robotic cells;  and a lower bound. The extensive experiments show that the proposed method performs better than FIFO and the swap sequence; moreover;  the gap between the makespan of the proposed method and the lower bound is not large. \n<italic xmlns:mml=\http://www.w3.org/1998/Math/MathML\ xmlns:xlink=\http://www.w3.org/1999/xlink\>