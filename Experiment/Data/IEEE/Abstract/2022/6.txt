This article presents a demand response scheduling model in a residential community using an energy management system aggregator. The aggregator manages a set of resources;  including photovoltaic system;  energy storage system;  thermostatically controllable loads;  and electrical vehicles. The solution aims to dynamically control the power demand and distributed energy resources to improve the matching performance between the renewable power generation and the consumption at the community level while trading electricity in both day-ahead and real-time markets to reduce the operational costs in the aggregator. The problem can be formulated as a mixed-integer linear programming problem in which the objective is to minimize the operation and the degradation costs related to the energy storage system and the electric vehicles batteries. To mitigate the uncertainties associated with system operation;  a two-level model predictive control (MPC) integrating \n<inline-formula xmlns:mml=\http://www.w3.org/1998/Math/MathML\ xmlns:xlink=\http://www.w3.org/1999/xlink\> <tex-math notation=\LaTeX\>$Q$ </tex-math></inline-formula>\n-learning reinforcement learning model is designed to address different time-scale controllers. MPC algorithm allows making decisions for the day-ahead;  based on predictions of uncertain parameters;  whereas \n<inline-formula xmlns:mml=\http://www.w3.org/1998/Math/MathML\ xmlns:xlink=\http://www.w3.org/1999/xlink\> <tex-math notation=\LaTeX\>$Q$ </tex-math></inline-formula>\n-learning algorithm addresses real-time decisions based on real-time data. The problem is solved for various sets of houses. Results demonstrated that houses can gain more benefits when they are operating in the aggregate mode.