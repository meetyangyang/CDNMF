Defect classification and detection have been explored using convolutional neural networks (CNNs). Normally;  a large set of training images containing defects and the associated annotation data are required by these approaches. However;  such a large set of images is usually difficult to collect because defects are rare and annotation is time-consuming and expensive. To address these issues;  we propose to use a multitask deep one-class CNN for defect classification. Compared with supervised classification methods;  this CNN does not require abnormal images and annotated data for training. Specifically;  we build a stacked encoderâ€“decoder autoencoder for learning feature representation from normal images. The encoder is used as a feature extractor based on the hard sharing scheme of multitask learning. A one-class classification (OCC) objective learned as a hypersphere using minimum volume estimation is appended to it. Together the encoder and the OCC objective lead to a deep one-class classifier. To train both the autoencoder and one-class classifier end-to-end;  a multitask loss function is built. Given an unknown sample;  the distance between its feature representation and the center of the hypersphere is used as the anomaly score. Furthermore;  defect detection is implemented using a moving-window scanning method on top of the deep one-class classifier. The proposed approach achieves better performance than its counterparts trained using a two-stage method. For defect detection;  our approach achieves results almost as good as the supervised method even without using any annotated data. We attribute the promising results to the advantages of multitask learning. \n<italic xmlns:mml=\http://www.w3.org/1998/Math/MathML\ xmlns:xlink=\http://www.w3.org/1999/xlink\>