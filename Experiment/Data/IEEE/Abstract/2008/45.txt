The maintenance problem with safety-critical components is significant for the economical benefit of companies. Motivated by a practical asset maintenance project;  a new joint replacement maintenance problem is introduced in this paper. The dynamics of the problem are modelled as a Markov decision process;  whose action space increases exponentially with the number of safety-critical components in the asset. To deal with the curse of dimensionality;  we identify a key property of the optimal solution: the optimal performance can always be achieved in a class of policies which satisfy the so-called shortest-remaining-lifetime-first (SRLF) rule. It reduces the action space from 0(2\n<sup xmlns:mml=\http://www.w3.org/1998/Math/MathML\ xmlns:xlink=\http://www.w3.org/1999/xlink\>n</sup>\n) to O(n);  where n is the number of safety-critical components. To further speed up the optimization procedure;  some interesting properties of the optimal policy are derived. Combining the SRLF rule and the neuro-dynamic programming (NDP) methodology;  we develop an efficient on-line algorithm to optimize this maintenance problem. This algorithm can handle the difficulties of large state space and large action space. Besides the theoretical proof;  the optimality and efficiency of the SRLF rule and the properties of the optimal policy are also illustrated by numerical examples. This work can shed some insights to the maintenance problems in a more general situation. 