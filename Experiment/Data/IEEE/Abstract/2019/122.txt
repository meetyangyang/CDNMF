In this paper;  we present a method to learn (infer) and refine a set of advices from the trajectories generated in the successful and failed attempts in a task or game;  in the form of advisory signal temporal logic (STL) formulas. Each advice consists of an advisory motion STL formula that characterizes the spatial-temporal pattern of the motion as a feature of success and an advisory selection STL formula as a criterion for the environment to select the advice. For the inference of advisory STL formulas;  we provide a theoretical framework of perfect classification with a labeled set of trajectories with different time lengths. We design an advisory controller that can drive the robots to satisfy an advisory motion STL formula based on the advice selected according to the advisory selection STL formula. The advisory controller can advise or guide the human operators or the robots for better performance with the shared autonomy between the human operator and the controller. We provide two case studies to test the effectiveness of the advisory controller;  one with a Baxter-On-Wheels simulator and the other with two quadrotors in an experimental testbed in iteratively improving the success rates of completing the tasks with the help of the designed advisory controller. 