This paper presents a high-performance vision-based precision manipulation technique that does not rely on an object;  contact;  or gripper model;  which are challenging and often times impractical to acquire. Instead;  we utilize a simple process model that roughly maps object velocities to actuator velocities;  and we maintain system efficiency and robustness via advanced vision-based control techniques with disturbance rejection mechanisms. For obtaining simple models;  we derive a set of actuator coordination rules for achieving common task space motions. The performance degradation due to modeling inaccuracies is then minimized via the model predictive control framework and a correction matrix method. Our experimental results show that the proposed strategy results in high-performance precision manipulation with minimal modeling effort. 