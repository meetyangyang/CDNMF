Foreground moving object segmentation is a fundamental problem in many computer vision applications. As a solution for foreground segmentation;  background modeling has been intensively studied over past years and many effective algorithms have been developed. However;  accurate foreground segmentation is still a difficult problem. Currently;  most of the algorithms work solely within the color space;  in which the segmentation performance is prone to be degraded by a multitude of challenges;  such as illumination changes;  shadows;  automatic camera adjustments;  and color camouflage. RGB-D cameras are active visual sensors that provide depth measurements along with color images. We present in this paper an innovative background modeling method by using both the color and depth information from an RGB-D camera. The proposed method is evaluated using a public RGB-D data set. Various experiments confirm that our method is able to achieve superior performance compared with existing well-known methods. 