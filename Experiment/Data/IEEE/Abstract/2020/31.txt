Visual localization has been well studied in recent decades and applied in many fields as a fundamental capability in robotics. However;  the success of the state of the arts usually builds on the assumption that the environment is static. In dynamic scenarios where moving objects are present;  the performance of the existing visual localization systems degrades a lot due to the disturbance of the dynamic factors. To address this problem;  we propose a novel sparse motion removal (SMR) model that detects the dynamic and static regions for an input frame based on a Bayesian framework. The similarity between the consecutive frames and the difference between the current frame and the reference frame are both considered to reduce the detection uncertainty. After the detection process is finished;  the dynamic regions are eliminated while the static ones are fed into a feature-based visual simultaneous localization and mapping (SLAM) system for further visual localization. To verify the proposed method;  both qualitative and quantitative experiments are performed and the experimental results have demonstrated that the proposed model can significantly improve the accuracy and robustness for visual localization in dynamic environments.<;/p><;p><;i>