Snap-fit assemblies are widely used in the manufacturing of several product types;  allowing part joining;  while the parts remain unprocessed. The locking mechanism of a snap-fit is usually done within the object structure;  not allowing visual identification of the successful process completion. Humans consider the forces developed between the two parts or the snapping sound;  as an indication of success. This is difficult to realize in robotic assembly;  and the process success is usually identified at a product quality control stage. The aim of this article is to migrate the human ability to identify a successful snap assembly to autonomous robotic assembly;  via a machine learning framework;  enabled by human-robot collaboration for rich data collection and labeling. The proposed framework allows learning while minimizing complexity;  cost;  and time. A generic feature set is proposed;  which can produce good identification results in different snap assembly types. A feature transformation is also introduced that is fundamental for the real-time operation of the proposed framework and the identification of successful snap-assemblies. Three different objects are used to experimentally validate the approach using a KUKA LWR4+ robotic arm;  resulting in high classification and real-time identification accuracy. Finally;  a comparison with a model-based method is conducted. 