Intelligent systems and advanced automation are involved in information collection and evaluation;  decision-making;  and the implementation of chosen actions. In such systems;  human responsibility becomes equivocal. Understanding human causal responsibility is particularly important when systems can harm people;  as with autonomous vehicles or;  most notably;  with autonomous weapon systems (AWSs). Using information theory;  we developed a responsibility quantification (ResQu) model of human causal responsibility in intelligent systems and demonstrated its applications on decisions regarding AWS. The analysis reveals that comparative human responsibility for outcomes is often low;  even when major functions are allocated to the human. Thus;  broadly stated policies of keeping humans in the loop and having meaningful human control are misleading and cannot truly direct decisions on how to involve humans in advanced automation. The current model assumes stationarity;  full knowledge regarding the characteristic of the human and automation;  and ignores temporal aspects. It is an initial step toward the development of a comprehensive responsibility model that will make it possible to quantify human causal responsibility. The model can serve as an additional tool in the analysis of system design alternatives and policy decisions regarding human causal responsibility;  providing a novel;  quantitative perspective on these matters. 