Predicting the occupancy of a human in real time is of great interest in human-robot coexistence for obtaining regions that a robot should avoid in safe motion planning. The human body is composed of joints and links;  suiting approximation by a kinematic chain;  but the control strategy of the human is completely unknown;  meaning the potential occupancy grows very fast and it is difficult to compute tightly in real time. As such;  most previous work considers only specific;  known;  or probable movements;  and usually does not account for a range of human dimensions. Focusing on the human arm;  we analyze archetypal movements performed by test subjects to create a dynamic model. Motion-capture data of subjects are fitted;  for modeling purposes;  to two abstractions: a 4-degree of freedom (DOF) model and a 3-DOF model;  to obtain dynamic parameters. We validate our approach on movements from a publicly available database. The prediction is shown to be computationally fast;  and reachable sets of the abstraction are shown to enclose all possible future occupancies of the arm for different subjects;  tightly but overapproximatively. The 3DOF model has advantages over the 4-DOF in terms of speed;  though the 4-DOF model is tighter at smaller time horizons. Such an overapproximative representation is intended for certifiable safety-guaranteed collision avoidance algorithms for robots. 