This paper presents a strategy to guide a mobile ground robot equipped with a camera or depth sensor;  in order to autonomously map the visible part of a bounded 3-D structure. We describe motion planning algorithms that determine appropriate successive viewpoints and attempt to fill holes automatically in a point cloud produced by the sensing and perception layer. The emphasis is on accurately reconstructing a 3-D model of a structure of moderate size rather than mapping large open environments;  with applications for example in architecture;  construction;  and inspection. The proposed algorithms do not require any initialization in the form of a mesh model or a bounding box;  and the paths generated are well adapted to situations where the vision sensor is used simultaneously for mapping and for localizing the robot;  in the absence of additional absolute positioning system. We analyze the coverage properties of our policy;  and compare its performance with the classic frontier-based exploration algorithm. We illustrate its efficacy for different structure sizes;  levels of localization accuracy;  and range of the depth sensor;  and validate our design on a real-world experiment. 