This paper was motivated by the problemof automatically recognizing human behavior and interactionsin a smart home environment. The smart home environment isequipped with cameras and microphones that permit the observation of human activity in the scene. The objective is firstto visualize the perceived human activities (e.g., for videoconferencing or surveillance of elderly people), and then to provideappropriate services based on these activities. We adopt a layeredapproach for human activity recognition in the environment.The layered framework is motivated by the human perception ofhuman behavior in the scene (white box). The system first recognizes basic activities of individuals, called roles, like “interactingwith table” or “walking.” Then, based on the recognized individualroles, group situations like “aperitif,” “presentation,” or “siesta"are recognized. In this paper, we describe an implementation thatis based on a 3-D video tracking system, as well as speech activitydetection using head set microphones. We evaluated the system for offline (a posteriori) situation classification and online (in scenario)situation recognition. A prototype system has been realized andinstalled at France Télécom R&D, visualizing current humanbehavior in the smart home to a distant user using a web interface.An open issue is still the detection of group dynamics and groupformation, which is necessary for group situation recognition in(informal) real settings.
