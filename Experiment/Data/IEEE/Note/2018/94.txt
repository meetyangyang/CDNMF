The objective of this paper is to automate the process of building a 3-D model of a structure of interest that is as complete as possible, using a mobile camera or depth sensor, in the absence of any prior information about this structure. Given that increasingly robust solutions for the visual simultaneous localization and mapping problem are now readily available, the key challenge that we address here is to develop motion planning policies to control the trajectory of the sensor in a way that improves the mapping performance. We target in particular scenarios where no external absolute positioning system is available, such as mapping certain indoor environments where GPS signals are blocked. In this case, it is often important to revisit previously seen locations relatively quickly, in order to avoid excessive drift in the dead-reckoning localization system. Our system works by first determining the boundaries of the structure, before attempting to fill the holes in the constructed model. Its performance is illustrated through simulations, and a real-world experiment performed with a depth sensor carried by a mobile manipulator.
