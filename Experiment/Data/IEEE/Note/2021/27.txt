This article was motivated by twopractical problems in computer vision for wearable robots:First, the performance of deep neural networks is challengedby real-life disturbances. However, reliable confidence estimationis usually unavailable and the factors causing failures are hard toidentify. Second, evaluating wearable robots by intuitive trial anderror is expensive due to the need for human experiments. Ourframework produces a calibrated predicted probability as wellas three uncertainty measures. The calibrated probability makesit easy to customize prediction decision criteria by consideringhow much the corresponding application can tolerate error.This study demonstrated a practical procedure to interpretand improve the performance of deep neural networks withuncertainty quantification. We anticipate that our methodologycould be extended to other applications as a general scientific and efficient procedure of evaluating and improving intelligentsystems.
