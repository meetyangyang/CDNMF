/i>\nâ€”Robotic systems need to adapt to sensor measurements and learn to exploit an understanding of the world around them such that they can truly begin to experiment in the real world. Standard learning methods do not have any restrictions on how the robot can explore and learn;  making the robot dynamically volatile. Those that do are often too restrictive in terms of the stability of the robot;  resulting in a lack of improved learning due to poor data collection. Applying our method would allow robotic systems to be able to adapt online without the need for human intervention. We show that considering both the dynamics of the robot and the statistics of where the robot has been;  we are able to naturally encode where the robot needs to explore and collect measurements for efficient learning that is dynamically safe. With our method;  we are able to effectively learn while being energetically efficient compared with state-of-the-art active learning methods. Our approach accomplishes such tasks in a single execution of the robotic system;  i.e.;  the robot does not need human intervention to reset it. Future work will consider multiagent robotic systems that actively learn and explore in a team of collaborative robots. 
