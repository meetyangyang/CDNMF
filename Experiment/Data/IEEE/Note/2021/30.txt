In this article;  the problem of human hand gesture recognition is analyzed using deep learning techniques. The proposed model uses input historical motion sequences collected from a wearable capacitance sensor to predict hand gestures. The model leverages the intrinsic correlation of motion sequences and extracts the salient part of the sequences by taking into consideration their temporal;  complex;  and nonlinear features. The approach studies the effect of different lengths of historical motion sequences in prediction outcomes. This allows for avoiding using cumbersome data collection;  heavy data treatment;  and high computational cost. The model performance is trained and assessed on real-world data by performing comparisons with alternative approaches;  including well-known classifiers. The model yields very encouraging results and demonstrates that the proposed approach is quite competitive as it can reproduce typical activity trends for important channels. The present findings could help in the development of intelligent wearable devices for predicting hand gestures using a limited number of channels. This work could also help practitioners to provide a more qualitative appraisal of patients suffering from different pathologies such as Parkinson's diseases to personalized healthcare-related applications and to develop wearable gesture recognition devices on a large scale. 
