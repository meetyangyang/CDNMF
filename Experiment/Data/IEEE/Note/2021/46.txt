/i>\nâ€”This article was motivated by two observations. On the one hand;  in robotics applications where uncertainty in sensing and actions is present;  the solution to the classical partially observable Markov decision process (POMDP) formulation is expensive to compute in general. On the other hand;  in certain practical scenarios;  formulations other than the classical POMDP make a lot of sense and can provide flexibility in balancing efficiency and correctness. This article considers a modified POMDP formulation that includes a Boolean objective;  namely safe reachability. This article uses the notion of a partial conditional plan. Rather than explicitly enumerating all possible observations to construct a full conditional plan;  this work samples a subset of all observations to ensure bounded replanning probability. Our theoretical and empirical results show that the failure rate of the constructed partial conditional plan is bounded by the replanning probability. Moreover;  these partial conditional plans can be cached to further improve the performance. Our results suggest that for domains where replanning is easy;  increasing the replanning probability bound usually leads to better scalability;  and for domains where replanning is difficult or impossible in some states;  we can decrease the bound and allocate more computation time to achieve a higher success rate. Hence;  in certain cases;  the practitioner can take advantage of their knowledge of the problem domain to scale to larger problems. Preliminary physical experiments suggest that this approach is applicable to real-world robotic domains;  but it requires a discrete representation of the workspace. How to deal with continuous workspace directly is an interesting future direction. 
