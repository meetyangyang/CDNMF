/i>\nâ€”This article investigates the problem of semantic segmentation of urban scenes when lighting conditions are not satisfied. We provide a solution to this problem via information fusion with RGB and thermal data. We build an end-to-end deep neural network;  which takes as input a pair of RGB and thermal images and outputs pixel-wise semantic labels. Our network could be used for urban scene understanding;  which serves as a fundamental component of many autonomous driving tasks;  such as environment modeling;  obstacle avoidance;  motion prediction;  and planning. Moreover;  the simple design of our network allows it to be easily implemented using various deep learning frameworks;  which facilitates the applications on different hardware or software platforms. 
