Autonomous robots perceive the worldusing sensors and then typically use the perceived data to manipulate or physically interact with the world, thus changing its state.One of the challenges of making robots useful in households andeveryday life is to make them capable of understanding their surroundings well. However, home and office environments are usually unstructured and cluttered. This introduces errors in perception and can lead to manipulation failures. This paper explores theidea that manipulation of the world to enable efficient perceptioncan in turn improve performance on the overall manipulation task.This suggests a paradigm shift in the way robots interact with theirenvironments. Traditionally, most of the objects in the environment are considered obstacles and any contact with them is considered a collision. We present an algorithm that uses simple actionsto manipulate a cluttered scene to improve the robot's perceptual,(and hence) grasping and sorting abilities. Our encouraging resultsdemonstrate substantial improvement on sorting tasks by insertingmanipulation aids into the task operation. We believe that deliberate manipulation of unstructured environments by robots wouldbe crucial to their introduction into our homes.
