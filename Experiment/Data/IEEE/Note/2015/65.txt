This paper was motivated by the necessary mobility needs of visually impaired and blind people.According to a review, the top listed accidents they experiencedwere head-level collision and motion collision, even though theywere using assistive devices. Currently, assistive devices are available to emulate missed functions due to vision loss, such as textreading, object recognition, and knee-level obstacle avoidance(e.g., smart canes), but they do not provide the solution to thefundamental problems as raised in the review. The research teamis developing a wearable blind navigator based on Google Glass.The target function modules include traversable region detection,motion estimation, and scene dynamics analysis. The ego-motionestimation method presented in this paper is part of the motionestimation module. The experiments on real scenarios suggest thatthis approach is feasible and effective. In future research, we willaddress the problems of robustness and real-time performance insystem implementation.
