Given the current manual review of colonoscopy is laborious and time-consuming, computational methods that can assist automatic polyp recognition will enhance the outcome both in terms of efficiency and diagnostic accuracy of colonoscopy. This article suggests a new approach using a very deep convolutional neural network (CNN) architecture for polyp recognition, which gains accuracy from deeper and richer representations. The method, called PLPNet, can effectively detect polyps in colonoscopy images and generate high-quality segmentation masks in a pixel-to-pixel manner. We evaluate the proposed framework on publicly available data sets, and we show by experiments that our method surpasses the stateof-the-art polyp recognition results. The finding of this article corroborates that CNNs with very deep architecture and richer semantics are highly efficient in medical image learning and inference. We believe that the proposed method will facilitate potential computer-aided applications in clinical practice, in that it can enhance medical decision-making in cancer detection and imaging.
