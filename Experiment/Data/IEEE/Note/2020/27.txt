This article was motivated by the lack of a simple and effective solution for the generation of data sets usable to train a data-driven model;  such as a modern deep neural network;  so as to make them accessible in an industrial environment. Specifically;  a deep learning robot guidance vision system would require such a large amount of manually labeled images that it would be too expensive and impractical for a real use case;  where system reconfigurability is a fundamental requirement. With our system;  on the other hand;  especially in the field of industrial robotics;  the cost of image labeling can be reduced;  for the first time;  to nearly zero;  thus paving the way for self-reconfiguring systems with very high performance (as demonstrated by our experimental results). One of the limitations of this approach is the need to use a manual method for the detection of objects of interest in the preliminary stages of the pipeline (ARP or graphical interface). A feasible extension;  related to the field of collaborative robotics;  could be used to exploit the robot itself;  manually moved by the user;  even for this preliminary stage;  so as to eliminate any source of inaccuracy. 
