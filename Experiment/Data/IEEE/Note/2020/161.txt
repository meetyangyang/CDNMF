This article was motivated by the visual localization problem of mobile robots in dynamic working environments. Visual localization is an important and fundamental capability in robotics. When a mobile robot is in an unknown environment, one important thing is to localize itself using the data collected from the perception sensors. In real scenes, the current localization algorithms often suffer from moving objects. The existence of moving objects, especially humans, brings a lot of noise into the localization process, which poses a big challenge and makes the robotic implementation unstable. In this article, a novel strategy is designed to handle this problem. We leverage both the object detection result and observation information in a Bayesian framework for dynamic region detection. Once the dynamic regions are determined, we discard them and feed the other regions in a state-of-the-art visual simultaneous localization and mapping system for further visual localization. The proposed strategy greatly improves the localization accuracy in dynamic working environments and guarantees the robustness for robotic implementation.
