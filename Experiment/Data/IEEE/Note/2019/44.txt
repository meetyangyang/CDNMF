Cross-modal retrieval is an important task for industrial intelligence. In this paper;  we establish a framework to effectively solve the cross-modal material retrieval problem. In the developed framework;  the user may submit a multimodal query including acceleration and sound about an object;  and the system may return the most relevant retrieved images. Such a framework may find extensive applications in many fields;  because it can be flexible to deal with a multiple-modal query and uses the minimal category label supervision without the need of strong sample pairing information between modalities. Compared with the previous material analysis systems;  this paper goes beyond previously proposed surface material classification approaches as it returns an ordered list of perceptually similar surface materials for a query. 
