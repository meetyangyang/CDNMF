The paper studies \safety\ control of stochastic systems modeled as Markov chains. Safety is defined as a requirement that the probability distribution in each state remain bounded between an upper and a lower bound. For example;  a financial investment policy should be such that the probability of ever being bankrupt is bounded below by a positive number. Prior works on control of Markov chains have addressed optimality but not safety. A condition is obtained under which a controlled Markov chain is guaranteed to be safe at all times. For those chains that do not satisfy such a condition;  a maximal subset of the safe set of distributions is computed so that if the chain is initialized with a distribution in that maximal subset;  it remains safe all the times. A condition is obtained under which such a maximal set is nonempty. The computation of such a maximal set is iterative and we provide a condition under which the computation terminates in a finite number of iterations. Manufacturing system examples are included to illustrate the results. 
