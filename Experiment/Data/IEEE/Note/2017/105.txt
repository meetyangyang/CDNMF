As dexterous robotic hands and general purpose grippers are becoming commercially available, we are motivated to explore their flexibility for griping a variety of automotive general assembly parts. Our experience has proven that extensive manual teaching or training or learning of a variety of grasps for each part in different physical environment is both time-consuming and impractical for high volume production. In addition, all pre-computed or trained grasps in grasp database establish one-to-one relationship between a specific part and a specific robotic hand. Therefore, it is difficult to utilize a grasp database due to changes in the physical environment for a specific part. For these reasons, we aim to develop a real-time grasp planner that does not rely on any pre-computed grasp database. Our real-time grasp planner takes advantage of the physical environment, such as tables or boxes, in bin-picking and kitting applications. We have discovered two effective strategies, the “intersected volume” and the “finger curling planes,” which enable us to achieve the real-time performance of less than 1 s. Our grasp planner utilizes two independent geometric models: 3-D shape model of parts and the robotic hand kinematic model that represents the hand’s spatial capability, i.e., the grasp volume. Two real-time inputs to our grasp planner are 6-D pose of a part and its physical environment information. Our current limitations are planar environment and untangled parts. Our experiments with two physical platforms have proven that realtime grasp planning and the direct execution of planned grasps in real-time is feasible and implementable.
