/i>\nâ€”The complicated assembly environment of the multiple peg-in-hole assembly results in a contact state that cannot be recognized exactly from the force sensor. Therefore;  contact-model-based methods that require tuning of the control parameters based on the contact state recognition cannot be applied directly in this complicated environment. Recently;  reinforcement learning (RL) methods without contact state recognition have recently attracted scientific interest. However;  the existing RL methods still rely on numerous explorations and a long training time;  which cannot be directly applied to real-world tasks. This article takes inspiration from the manner in which human beings can learn assembly skills with a few trials;  which relies on the variable time-scale predictions (VTSPs) of the environment and the optimized assembly action control strategy. Our proposed fuzzy logic-driven variable time-scale prediction-based reinforcement learning (FLDVTSP-RL) can be implemented in two steps. First;  the assembly environment is predicted by the VTSP defined as general value functions (GVFs). Second;  assembly action control is realized in an impedance action space with a baseline defined by the impedance parameter mapped from the predicted environment by the fuzzy logic system (FLS). Finally;  a dual peg-in-hole assembly experiment is conducted; compared with deep Q-learning (DQN);  FLDVTSP-DQN can decrease the assembly time about 44%; compared with deep deterministic policy gradient (DDPG);  FLDVTSP-DDPG can decrease the assembly time about 24%. 
